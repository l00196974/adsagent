#!/usr/bin/env python3
"""
æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–è„šæœ¬
ä¸ºå…³é”®æŸ¥è¯¢è·¯å¾„æ·»åŠ ç´¢å¼•ï¼Œæå‡æŸ¥è¯¢æ€§èƒ½5-10å€

æ‰§è¡Œæ–¹å¼ï¼š
    cd backend
    python scripts/add_performance_indexes.py
"""

import sqlite3
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.core.logger import app_logger


def add_indexes(db_path: str = "data/graph.db"):
    """æ·»åŠ æ€§èƒ½ä¼˜åŒ–ç´¢å¼•"""

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    indexes_to_create = [
        # behavior_data å¤åˆç´¢å¼•ï¼šä¼˜åŒ–æŒ‰ç”¨æˆ·å’Œæ—¶é—´èŒƒå›´æŸ¥è¯¢
        ("idx_behavior_user_time", "behavior_data", ["user_id", "timestamp"]),

        # behavior_data actionç´¢å¼•ï¼šä¼˜åŒ–æŒ‰è¡Œä¸ºç±»å‹è¿‡æ»¤
        ("idx_behavior_action", "behavior_data", ["action"]),

        # extracted_events å¤åˆç´¢å¼•ï¼šä¼˜åŒ–æŒ‰ç”¨æˆ·å’Œæ—¶é—´æŸ¥è¯¢
        ("idx_extracted_events_user_time", "extracted_events", ["user_id", "timestamp"]),

        # extracted_events event_typeç´¢å¼•ï¼šä¼˜åŒ–æŒ‰äº‹ä»¶ç±»å‹è¿‡æ»¤
        ("idx_extracted_events_type", "extracted_events", ["event_type"]),

        # event_sequences æ—¶é—´èŒƒå›´ç´¢å¼•ï¼šä¼˜åŒ–æ—¶é—´èŒƒå›´æŸ¥è¯¢
        ("idx_event_sequences_time", "event_sequences", ["start_time", "end_time"]),

        # frequent_patterns æ”¯æŒåº¦ç´¢å¼•ï¼šä¼˜åŒ–æŒ‰æ”¯æŒåº¦æ’åº
        ("idx_frequent_patterns_support", "frequent_patterns", ["support"]),

        # causal_rules ç½®ä¿¡åº¦ç´¢å¼•ï¼šä¼˜åŒ–æŒ‰ç½®ä¿¡åº¦æ’åº
        ("idx_causal_rules_confidence", "causal_rules", ["confidence"]),
    ]

    created_count = 0
    skipped_count = 0

    for index_name, table_name, columns in indexes_to_create:
        try:
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
            cursor.execute(
                "SELECT name FROM sqlite_master WHERE type='index' AND name=?",
                (index_name,)
            )
            if cursor.fetchone():
                app_logger.info(f"ç´¢å¼• {index_name} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                skipped_count += 1
                continue

            # åˆ›å»ºç´¢å¼•
            columns_str = ", ".join(columns)
            sql = f"CREATE INDEX {index_name} ON {table_name} ({columns_str})"

            app_logger.info(f"åˆ›å»ºç´¢å¼•: {sql}")
            cursor.execute(sql)
            created_count += 1

        except Exception as e:
            app_logger.error(f"åˆ›å»ºç´¢å¼• {index_name} å¤±è´¥: {e}")

    conn.commit()
    conn.close()

    app_logger.info(f"ç´¢å¼•ä¼˜åŒ–å®Œæˆ: åˆ›å»º {created_count} ä¸ªï¼Œè·³è¿‡ {skipped_count} ä¸ª")
    print(f"\nâœ… ç´¢å¼•ä¼˜åŒ–å®Œæˆ:")
    print(f"   - æ–°åˆ›å»º: {created_count} ä¸ªç´¢å¼•")
    print(f"   - å·²å­˜åœ¨: {skipped_count} ä¸ªç´¢å¼•")
    print(f"\né¢„æœŸæ€§èƒ½æå‡: 5-10å€")


def analyze_indexes(db_path: str = "data/graph.db"):
    """åˆ†æå½“å‰ç´¢å¼•ä½¿ç”¨æƒ…å†µ"""

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    print("\n=== å½“å‰æ•°æ®åº“ç´¢å¼• ===\n")

    # è·å–æ‰€æœ‰è¡¨
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
    tables = [row[0] for row in cursor.fetchall()]

    for table in tables:
        # è·å–è¡¨çš„ç´¢å¼•
        cursor.execute(f"PRAGMA index_list({table})")
        indexes = cursor.fetchall()

        if indexes:
            print(f"ğŸ“Š {table}:")
            for idx in indexes:
                index_name = idx[1]
                is_unique = "UNIQUE" if idx[2] else "INDEX"

                # è·å–ç´¢å¼•åˆ—
                cursor.execute(f"PRAGMA index_info('{index_name}')")
                cols = [c[2] for c in cursor.fetchall()]
                cols_str = ", ".join(cols)

                print(f"   - {is_unique}: {index_name} ({cols_str})")
            print()

    conn.close()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å·¥å…·")
    parser.add_argument("--analyze", action="store_true", help="åˆ†æå½“å‰ç´¢å¼•")
    parser.add_argument("--db", default="data/graph.db", help="æ•°æ®åº“è·¯å¾„")

    args = parser.parse_args()

    if args.analyze:
        analyze_indexes(args.db)
    else:
        add_indexes(args.db)
        analyze_indexes(args.db)
